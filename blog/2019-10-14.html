<!DOCTYPE html>
<html lang="en">

    <!-- Ibis Cybernetics Blog Index -->

    <!-- Head begins here -->
    <head>
        <meta charset="utf-8" />
        <meta name="description" content="Ibis Cybernetics Corporation" />
        <meta name="keywords" content="software,c,php,artwork,pixel art,robotics,cybernetics" />
        <meta name="robots" content="index,follow" />
        <meta name="author" content="Robert Bisewski" />

        <!-- css -->
        <link rel="stylesheet" href="ibis_cybernetics_blog.css">

        <!-- favicon -->
        <link href="../ibis.ico" rel="shortcut icon" type="image/x-icon" />

        <!-- assign a title to this page -->
        <title>Cyberia Blog - Ibis Cybernetics Corporation</title>
    </head>

    <!-- Body begins here -->
    <body>

        <!-- Blog entry content goes here -->
        <div class="centre_content">

            <a href="index.html">&larr; back</a>

            <h1>
               2019-10-14: fundamentals of game audio design
            </h1>

            <br>

            <p>
               For audio speakers, which output analogue sound, the solution
               from the computer's point of view is to take the internal audio
               data and "sample it" using a technique known as pulse code
               modulation; typically 48,000 samples per second AKA 48kHz.
            </p>
                
            <p>
               However, this by itself only allows us to play a single sound,
               which is not that interesting. We can play more sounds by
               summing the waves of all of the output signals. Hence...
            </p>

            <p class="grey_monospace_code">
                audio output = sum(all signal waves)
            </p>
                
            <p>
               In order to get this to a sound card and actually play the
               sound, we need to use a specific structure called a
               <a href="https://en.wikipedia.org/wiki/Circular_buffer">circular buffer</a>
               which will store the data stream for use with the constant
               audio input/output that might occur in a game; e.g. from
               sound effects and music.
            </p>

            <p>
               A well designed circular buffer must guarantee; that it will
               allow any given value stored to be returned in less than the
               buffer length; that it can always finish processing the whole
               buffer; that the output contains valid audio data and with no
               exceptions or errors.
            </p>

            <p>
               In order to obtain the above requirements, this means the
               buffer must be implemented as a "mixer thread" that is spawned
               or declared by the program or an audio library. To create a
               proper mixer, it typically needs the following:
            </p>

            <ul class="paragraph_ul">
                <li>the mixer thread must run at high OS priority</li>
                <li>it must be block free, which means either lock-free (atomic) or wait-free</li>
                <li>no memory allocations or deallocations</li>
                <li>no I/O delay; e.g. console, IPC, disk, network, etc</li>
            </ul>

            <p>
               Since video games are real-time applications, this means that
               processor and memory and how they are used is very important.
               Yet there are a number of known options for dealing with this:
            </p>

            <ul class="paragraph_ul">
                <li>
                    decompress the file into memory (akin to PCM), reducing
                    CPU cost
                </li>
                <li>
                    copy the compressed file into memory and then decompress
                    it from the buffer, reducing memory cost
                </li>
                <li>
                    create another buffer layer and load it from an input
                    source, such as a microphone or disk, and <i>then</i>
                    buffer that into the original circular buffer
                </li>
                <li>
                    stream the data off of the disk (e.g. ifstream) using
                    a double buffer; this can be very helpful for large
                    audio files, such as music or ambience sounds
                </li>
                <li>
                    synthesize the audio in real-time, which only works well
                    if you want to entirely generate a piece of audio
                </li>
            </ul>

            <p>
               In most modern game design, typically some sort of middleware
               is provided to assist with the creation and playing of sounds
               or music during in-game events. Examples include; FMOD,
               AudioKinetic Wwise, CRI ADX2, while other game engines like
               Unity and Unreal feature their own middleware.
            </p>

            <p>
               Sounds that are currently playing are read from the buffer
               into elements called channels and in most middleware they
               offer features to check whether or not they are still playing
               sounds or if they are paused, as well as the ability to set
               the 3D position of the channel; i.e. sound emission origin.
            </p>

            <p>
               A good sound engine will be built as a
               <a href="https://en.wikipedia.org/wiki/Finite-state_machine">finite state machine</a>
               where it will be only in a single state at any given time
               and often have a variety of helpful features such as
               fadeouts, async loads, and virtual sounds. Such a state machine
               could have the following:
            </p>

            <ul class="paragraph_ul">
                <li>
                    a <i>playing</i> state for when sounds are playing
                </li>
                <li>
                    <i>stopping</i> and <i>stopped</i> states for
                    implementing fadeouts
                </li>
                <li>
                    for async loading, the <i>initialize</i> and <i>loading</i>
                    and <i>try-to-play / devirtualize</i> states are needed
                </li>
                <li>
                    virtual sounds need the <i>virtualizing</i> and
                    <i>virtual</i> states; where virtual sounds are sound
                    data that is important enough to keep track off but you 
                    the player may not actually hear them
                </li>
            </ul>

            <p>
               If the above are implemented into an audio engine, then the
               developers have quite a lot of functionality to utilize and
               this can allow the creation of effects, such as a
               low-pass-filter.
            </p>

            <br>
        </div>
    </body>
</html>
